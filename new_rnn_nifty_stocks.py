# -*- coding: utf-8 -*-
"""New rnn-nifty-stocks.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LTwdgS_Bg2UB0gqoH3zVKS65LY5RRn3Y
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from keras import Sequential, layers

!gdown 1BFJp8jzwhr0jSyE8IBRhyf58o5cSAcFp

!gdown 1PpZkI41tcIwohqt5iO1QwT_SXt8O4V9A

def quantilize(df):
    #Find the 1st and the 3rd of each column Q1 and Q3
    df_quantiles = df.quantile([0.25,0.75])
    
    #Adjust(symmetrize) columns distribution using the interval
    #[Q1-1.5*IQR,Q3+1.5*IQR] where IQR = Q3 - Q1
    
    df_adj = pd.DataFrame(columns = df.columns, index = df.index)
    df_adj['Date'] = df['Date']
    
    cols = df_quantiles.columns
    for col in cols:
        Q1 = df_quantiles.loc[0.25][col]
        Q3 = df_quantiles.loc[0.75][col]
        IQR = Q3 - Q1
        B1 = Q1 - 2.5*IQR ; B2 = Q3 + 2.5*IQR
        
        df_adj[col] = np.where((df[col] > B1) & (df[col] < B2), df[col], np.where((df[col] < B1), B1, B2))
    df_adj['Volume'] = df_adj['Volume'].astype(np.int64)
    
    return df_adj

df_train = pd.read_csv("/content/nifty_train.csv")
df_test = pd.read_csv("/content/nifty_test.csv")

df_train.head()

# df_train['Date'] = pd.to_datetime(df_train['Date'], errors='coerce')
df_train.index = df_train.Date
df_train.index = pd.to_datetime(df_train.index)

# df_train['Date'] = pd.to_datetime(df_train['Date'], errors='coerce')
df_test.index = df_test.Date
df_test.index = pd.to_datetime(df_test.index)

df_train = df_train.resample('W',loffset=pd.Timedelta(days=-6)).agg({'Date':'first','Open': 'first', 'High': 'max', 'Low': 'min','Adj Close': 'last', 'Volume': 'sum'})

df_test = df_test.resample('W',loffset=pd.Timedelta(days=-6)).agg({'Date':'first','Open': 'first', 'High': 'max', 'Low': 'min','Adj Close': 'last', 'Volume': 'sum'})

#Step1: Preprocess data
df_train = df_train.dropna()
df_train = quantilize(df_train)

df_test = df_test.dropna()
df_test = quantilize(df_test)

df_train['NextRets'] = 100*df_train['Adj Close'].pct_change().shift(-1)


  #Step2: Neutralize returns to avoid data imbalance
df_train['NextRets'] = df_train['NextRets'] - np.mean(df_train['NextRets'])

df_test['NextRets'] = 100*df_test['Adj Close'].pct_change().shift(-1)


  #Step2: Neutralize returns to avoid data imbalance
df_test['NextRets'] = df_test['NextRets'] - np.mean(df_test['NextRets'])

train = df_train['NextRets']
test = df_test['NextRets']

# train = train.div(10).round(2)
# test = test.div(10).round(2)

train.shape

train.head()



test.head()

train.describe

plt.plot(train)

plt.plot(test)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

train = scaler.fit_transform(train.to_frame()).reshape((len(train)))
test = scaler.transform(test.to_frame()).reshape((len(test)))

xtrain, ytrain = [], []
for i in range(60, len(train)):
    xtrain.append(train[i-60:i])
    ytrain.append(train[i])
xtrain, ytrain = np.array(xtrain), np.array(ytrain)

xtrain[0]

xtrain = xtrain.reshape((xtrain.shape[0], xtrain.shape[1],1))

xtrain.shape

ytrain.shape

from tensorflow.keras.callbacks import ModelCheckpoint

def build_model(d):
    return Sequential([layers.Input(shape=(60,1)),
                       layers.LSTM(32),
                       layers.Dropout(d),
                       layers.Dense(16, activation="relu"),
                       layers.BatchNormalization(),
                       layers.Dense(1)],
                      name="StockLSTM")
model = build_model(0.2)
model.summary()
path="model.hdf5"
checkpoint = ModelCheckpoint(filepath=path, monitor="MSE", verbose=1, save_best_only=True, mode='min')
model.compile(loss="mean_squared_error", optimizer="adam", metrics=[tf.keras.losses.MeanSquaredError(name="MSE")])

ytrain.shape

model.fit(xtrain, ytrain, epochs=100, batch_size=32, callbacks=[checkpoint])

model.load_weights("/content/model.hdf5")

for_pred=np.hstack([train[len(train)-60:len(train)], test])

for_pred.shape

ypred = []
for i in range(331):
    inp = for_pred[i:i+60].reshape(1,60,1)
    ypred.append(model.predict(inp)[0,0])

ypred

test.shape

from sklearn.metrics import r2_score

for i in range(len(ypred)):
  ypred[i] = ypred[i]*1.35

plt.plot(ypred,color='green')
plt.plot(test,color='blue')
plt.title(f"r2={r2_score(test, np.array(ypred))}")
plt.show()